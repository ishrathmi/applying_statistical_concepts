{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0bcac6-5086-4f4e-928a-570a9ff7ae58",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0350-2a17-4e93-8d4c-0b8748fdfc32",
   "metadata": {},
   "source": [
    "You only need to write one line of code for each question. When answering questions that ask you to identify or interpret something, the length of your response doesn’t matter. For example, if the answer is just ‘yes,’ ‘no,’ or a number, you can just give that answer without adding anything else.\n",
    "\n",
    "We will go through comparable code and concepts in the live learning session. If you run into trouble, start by using the help `help()` function in Python, to get information about the datasets and function in question. The internet is also a great resource when coding (though note that **no outside searches are required by the assignment!**). If you do incorporate code from the internet, please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "Please bring questions that you cannot work out on your own to office hours, work periods or share with your peers on Slack. We will work with you through the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5001c-7715-4ebe-b0f7-e4bd04349629",
   "metadata": {},
   "source": [
    "### Classification using KNN\n",
    "\n",
    "Let's set up our workspace and use the **Wine dataset** from `scikit-learn`. This dataset contains 178 wine samples with 13 chemical features, used to classify wines into different classes based on their origin.\n",
    "\n",
    "The **response variable** is `class`, which indicates the type of wine. We'll use all of the chemical features to predict this response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a3485d6-ba58-4660-a983-5680821c5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a431d282-f9ca-4d5d-8912-71ffc9d8ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  class  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Convert to DataFrame\n",
    "wine_df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "# Bind the 'class' (wine target) to the DataFrame\n",
    "wine_df['class'] = wine_data.target\n",
    "\n",
    "# Display the DataFrame\n",
    "wine_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b2b17",
   "metadata": {},
   "source": [
    "#### **Question 1:** \n",
    "#### Data inspection\n",
    "\n",
    "Before fitting any model, it is essential to understand our data. **Use Python code** to answer the following questions about the **Wine dataset**:\n",
    "\n",
    "_(i)_ How many observations (rows) does the dataset contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56916892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  class                         178 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Your answer here\n",
    "#178 rows, with 177 data-containing rows\n",
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7573b59",
   "metadata": {},
   "source": [
    "_(ii)_ How many variables (columns) does the dataset contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df0ef103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "#14 columns as seen in the code above "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5180c7",
   "metadata": {},
   "source": [
    "_(iii)_ What is the 'variable type' of the response variable `class` (e.g., 'integer', 'category', etc.)? What are the 'levels' (unique values) of the variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47989426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here\n",
    "#integer (int64), and it has 3 unique levels/classes\n",
    "wine_df[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f5e1b",
   "metadata": {},
   "source": [
    "\n",
    "_(iv)_ How many predictor variables do we have (Hint: all variables other than `class`)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd7b0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "#12 predictor variables not including the ID for each entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631e8e3",
   "metadata": {},
   "source": [
    "You can use `print()` and `describe()` to help answer these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3832d7",
   "metadata": {},
   "source": [
    "#### **Question 2:** \n",
    "#### Standardization and data-splitting\n",
    "\n",
    "Next, we must preform 'pre-processing' or 'data munging', to prepare our data for classification/prediction. For KNN, there are three essential steps. A first essential step is to 'standardize' the predictor variables. We can achieve this using the scaler method, provided as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc899b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
      "0  1.518613   -0.562250  0.232053          -1.169593   1.913905   \n",
      "1  0.246290   -0.499413 -0.827996          -2.490847   0.018145   \n",
      "2  0.196879    0.021231  1.109334          -0.268738   0.088358   \n",
      "3  1.691550   -0.346811  0.487926          -0.809251   0.930918   \n",
      "4  0.295700    0.227694  1.840403           0.451946   1.281985   \n",
      "\n",
      "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
      "0       0.808997    1.034819             -0.659563         1.224884   \n",
      "1       0.568648    0.733629             -0.820719        -0.544721   \n",
      "2       0.808997    1.215533             -0.498407         2.135968   \n",
      "3       2.491446    1.466525             -0.981875         1.032155   \n",
      "4       0.808997    0.663351              0.226796         0.401404   \n",
      "\n",
      "   color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
      "0         0.251717  0.362177                      1.847920  1.013009  \n",
      "1        -0.293321  0.406051                      1.113449  0.965242  \n",
      "2         0.269020  0.318304                      0.788587  1.395148  \n",
      "3         1.186068 -0.427544                      1.184071  2.334574  \n",
      "4        -0.319276  0.362177                      0.449601 -0.037874  \n"
     ]
    }
   ],
   "source": [
    "# Select predictors (excluding the last column)\n",
    "predictors = wine_df.iloc[:, :-1]\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9981ca48",
   "metadata": {},
   "source": [
    "(i) Why is it important to standardize the predictor variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ef0bb",
   "metadata": {},
   "source": [
    "the larger the scale of a predictor variable, the more weight it has in the final prediction. Therefore all variables must be brought into a standard scale so no sinlge predictor variables has an inflated effect on the prediction outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e1bea",
   "metadata": {},
   "source": [
    "(ii) Why did we elect not to standard our response variable `Class`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee5a15",
   "metadata": {},
   "source": [
    "Because class is a 'classification' type variable, not a numerical variable. It has a fixed value and the outcome can only be one of three. It is easy to interpret and standarizing the outcome is meaningless and can make interpretation difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077ec21",
   "metadata": {},
   "source": [
    "(iii) A second essential step is to set a random seed. Do so below (Hint: use the random.seed function). Why is setting a seed important? Is the particular seed value important? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0676c21",
   "metadata": {},
   "source": [
    "A random seed number is used to introduce randomness into the model to make our evaluation fairer. \n",
    "\n",
    "The random number generator needs a 'seed value' to start with. The number we choose itself is not particularly important, but the number must remain the same through out our model deployment as we want the random numbers generated to remain the same. Changing the 'seed number' changes the random numbers outputted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28f74aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab9229",
   "metadata": {},
   "source": [
    "(iv) A third essential step is to split our standardized data into separate training and testing sets. We will split into 75% training and 25% testing. The provided code randomly partitions our data, and creates linked training sets for the predictors and response variables. \n",
    "\n",
    "Extend the code to create a non-overlapping test set for the predictors and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78a88a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False  True  True  True  True  True False  True  True False\n",
      "  True  True  True False  True  True  True  True  True  True False  True\n",
      "  True  True  True  True False  True False  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False  True  True  True  True  True False  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      " False  True  True  True  True False  True  True  True  True  True False\n",
      " False  True  True  True False False  True  True False  True  True  True\n",
      "  True False False  True  True  True  True  True  True  True False  True\n",
      "  True False  True  True  True False  True False  True  True  True  True\n",
      "  True False  True  True  True False  True  True  True False  True False\n",
      " False  True False  True False False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Do not touch\n",
    "np.random.seed(123)\n",
    "# Create a random vector of True and False values to split the data\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "print(split)\n",
    "wine_df_train = predictors_standardized[split]\n",
    "wine_df_test = predictors_standardized [~split]\n",
    "#wine_df_train.info()\n",
    "#wine_df_test.info()\n",
    "\n",
    "outcomes = wine_df.iloc[:,-1: ]\n",
    "outcome_test = outcomes[~split]\n",
    "outcome_train = outcomes[split]\n",
    "#outcome_test.info()\n",
    "#outcome_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ba752",
   "metadata": {},
   "source": [
    "code from: https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604ee03",
   "metadata": {},
   "source": [
    "#### **Question 3:**\n",
    "#### Model initialization and cross-validation\n",
    "We are finally set to fit the KNN model. \n",
    "\n",
    "\n",
    "Perform a grid search to tune the `n_neighbors` hyperparameter using 10-fold cross-validation. Follow these steps:\n",
    "\n",
    "1. Initialize the KNN classifier using `KNeighborsClassifier()`.\n",
    "2. Define a parameter grid for `n_neighbors` ranging from 1 to 50.\n",
    "3. Implement a grid search using `GridSearchCV` with 10-fold cross-validation to find the optimal number of neighbors.\n",
    "4. After fitting the model on the training data, identify and return the best value for `n_neighbors` based on the grid search results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d67f0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75558d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(outcome_train[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08818c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.045737</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.034993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>27</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>31</td>\n",
       "      <td>{'n_neighbors': 31}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_neighbors': 33}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>35</td>\n",
       "      <td>{'n_neighbors': 35}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>37</td>\n",
       "      <td>{'n_neighbors': 37}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>39</td>\n",
       "      <td>{'n_neighbors': 39}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.067386</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>41</td>\n",
       "      <td>{'n_neighbors': 41}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>43</td>\n",
       "      <td>{'n_neighbors': 43}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>45</td>\n",
       "      <td>{'n_neighbors': 45}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.084515</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>47</td>\n",
       "      <td>{'n_neighbors': 47}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.087190</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>49</td>\n",
       "      <td>{'n_neighbors': 49}</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.084515</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.000752      0.000468         0.001027        0.000236   \n",
       "1        0.000519      0.000091         0.000928        0.000099   \n",
       "2        0.000508      0.000062         0.000905        0.000061   \n",
       "3        0.000500      0.000054         0.000904        0.000069   \n",
       "4        0.000494      0.000067         0.000953        0.000135   \n",
       "5        0.000498      0.000027         0.000927        0.000112   \n",
       "6        0.000486      0.000024         0.000896        0.000034   \n",
       "7        0.000505      0.000070         0.000945        0.000104   \n",
       "8        0.000494      0.000040         0.000910        0.000049   \n",
       "9        0.000497      0.000050         0.000916        0.000044   \n",
       "10       0.000530      0.000106         0.000964        0.000113   \n",
       "11       0.000504      0.000073         0.000945        0.000127   \n",
       "12       0.000493      0.000050         0.000925        0.000055   \n",
       "13       0.000511      0.000073         0.000973        0.000156   \n",
       "14       0.000503      0.000066         0.000934        0.000067   \n",
       "15       0.000492      0.000041         0.000927        0.000062   \n",
       "16       0.000491      0.000037         0.000922        0.000072   \n",
       "17       0.000489      0.000038         0.000929        0.000056   \n",
       "18       0.000472      0.000008         0.000911        0.000033   \n",
       "19       0.000488      0.000020         0.000944        0.000085   \n",
       "20       0.000520      0.000091         0.000964        0.000088   \n",
       "21       0.000496      0.000067         0.000942        0.000072   \n",
       "22       0.000490      0.000053         0.000930        0.000042   \n",
       "23       0.000502      0.000058         0.000949        0.000062   \n",
       "24       0.000490      0.000024         0.000947        0.000075   \n",
       "\n",
       "    param_n_neighbors               params  split0_test_score  \\\n",
       "0                   1   {'n_neighbors': 1}           0.857143   \n",
       "1                   3   {'n_neighbors': 3}           0.928571   \n",
       "2                   5   {'n_neighbors': 5}           0.928571   \n",
       "3                   7   {'n_neighbors': 7}           1.000000   \n",
       "4                   9   {'n_neighbors': 9}           1.000000   \n",
       "5                  11  {'n_neighbors': 11}           1.000000   \n",
       "6                  13  {'n_neighbors': 13}           1.000000   \n",
       "7                  15  {'n_neighbors': 15}           0.928571   \n",
       "8                  17  {'n_neighbors': 17}           0.928571   \n",
       "9                  19  {'n_neighbors': 19}           1.000000   \n",
       "10                 21  {'n_neighbors': 21}           1.000000   \n",
       "11                 23  {'n_neighbors': 23}           1.000000   \n",
       "12                 25  {'n_neighbors': 25}           1.000000   \n",
       "13                 27  {'n_neighbors': 27}           1.000000   \n",
       "14                 29  {'n_neighbors': 29}           1.000000   \n",
       "15                 31  {'n_neighbors': 31}           1.000000   \n",
       "16                 33  {'n_neighbors': 33}           0.928571   \n",
       "17                 35  {'n_neighbors': 35}           0.928571   \n",
       "18                 37  {'n_neighbors': 37}           0.928571   \n",
       "19                 39  {'n_neighbors': 39}           0.928571   \n",
       "20                 41  {'n_neighbors': 41}           0.928571   \n",
       "21                 43  {'n_neighbors': 43}           0.928571   \n",
       "22                 45  {'n_neighbors': 45}           0.928571   \n",
       "23                 47  {'n_neighbors': 47}           0.928571   \n",
       "24                 49  {'n_neighbors': 49}           0.928571   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.928571           0.928571           0.928571   \n",
       "1            1.000000           0.928571           0.928571   \n",
       "2            0.928571           0.928571           1.000000   \n",
       "3            0.928571           0.928571           1.000000   \n",
       "4            0.928571           0.928571           0.928571   \n",
       "5            0.857143           0.928571           0.928571   \n",
       "6            0.857143           0.928571           0.928571   \n",
       "7            0.857143           0.928571           0.928571   \n",
       "8            0.857143           0.928571           0.928571   \n",
       "9            0.928571           0.857143           0.928571   \n",
       "10           0.928571           0.857143           0.928571   \n",
       "11           0.928571           0.857143           0.928571   \n",
       "12           0.928571           0.857143           0.928571   \n",
       "13           0.928571           0.857143           0.928571   \n",
       "14           0.928571           0.857143           0.928571   \n",
       "15           0.928571           0.857143           0.928571   \n",
       "16           0.928571           0.857143           0.928571   \n",
       "17           1.000000           0.857143           0.928571   \n",
       "18           1.000000           0.785714           0.928571   \n",
       "19           0.928571           0.785714           0.928571   \n",
       "20           1.000000           0.785714           0.928571   \n",
       "21           0.857143           0.785714           0.928571   \n",
       "22           0.928571           0.714286           0.928571   \n",
       "23           1.000000           0.714286           0.928571   \n",
       "24           1.000000           0.714286           0.928571   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0                 1.0           0.928571                1.0   \n",
       "1                 1.0           1.000000                1.0   \n",
       "2                 1.0           0.928571                1.0   \n",
       "3                 1.0           0.928571                1.0   \n",
       "4                 1.0           0.928571                1.0   \n",
       "5                 1.0           0.928571                1.0   \n",
       "6                 1.0           0.928571                1.0   \n",
       "7                 1.0           0.928571                1.0   \n",
       "8                 1.0           0.928571                1.0   \n",
       "9                 1.0           0.928571                1.0   \n",
       "10                1.0           0.928571                1.0   \n",
       "11                1.0           0.928571                1.0   \n",
       "12                1.0           0.857143                1.0   \n",
       "13                1.0           0.857143                1.0   \n",
       "14                1.0           0.857143                1.0   \n",
       "15                1.0           0.857143                1.0   \n",
       "16                1.0           0.857143                1.0   \n",
       "17                1.0           0.857143                1.0   \n",
       "18                1.0           0.857143                1.0   \n",
       "19                1.0           0.857143                1.0   \n",
       "20                1.0           0.857143                1.0   \n",
       "21                1.0           0.857143                1.0   \n",
       "22                1.0           0.857143                1.0   \n",
       "23                1.0           0.857143                1.0   \n",
       "24                1.0           0.857143                1.0   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            1.000000           0.857143           0.928571         0.935714   \n",
       "1            0.928571           0.857143           0.928571         0.950000   \n",
       "2            1.000000           0.928571           1.000000         0.964286   \n",
       "3            1.000000           0.928571           1.000000         0.971429   \n",
       "4            1.000000           0.928571           1.000000         0.964286   \n",
       "5            1.000000           1.000000           1.000000         0.964286   \n",
       "6            1.000000           1.000000           1.000000         0.964286   \n",
       "7            1.000000           1.000000           1.000000         0.957143   \n",
       "8            1.000000           1.000000           1.000000         0.957143   \n",
       "9            1.000000           1.000000           1.000000         0.964286   \n",
       "10           1.000000           1.000000           1.000000         0.964286   \n",
       "11           1.000000           0.857143           1.000000         0.950000   \n",
       "12           1.000000           0.928571           1.000000         0.950000   \n",
       "13           1.000000           0.928571           1.000000         0.950000   \n",
       "14           1.000000           0.928571           1.000000         0.950000   \n",
       "15           1.000000           0.928571           1.000000         0.950000   \n",
       "16           1.000000           0.928571           1.000000         0.942857   \n",
       "17           1.000000           0.928571           1.000000         0.950000   \n",
       "18           1.000000           0.928571           1.000000         0.942857   \n",
       "19           1.000000           0.928571           1.000000         0.935714   \n",
       "20           1.000000           0.928571           1.000000         0.942857   \n",
       "21           1.000000           0.928571           1.000000         0.928571   \n",
       "22           1.000000           0.928571           1.000000         0.928571   \n",
       "23           1.000000           0.928571           1.000000         0.935714   \n",
       "24           0.928571           0.928571           1.000000         0.928571   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.050000               20  \n",
       "1         0.045737               10  \n",
       "2         0.035714                2  \n",
       "3         0.034993                1  \n",
       "4         0.035714                2  \n",
       "5         0.047916                2  \n",
       "6         0.047916                2  \n",
       "7         0.047380                8  \n",
       "8         0.047380                8  \n",
       "9         0.047916                2  \n",
       "10        0.047916                2  \n",
       "11        0.055787               10  \n",
       "12        0.055787               10  \n",
       "13        0.055787               10  \n",
       "14        0.055787               10  \n",
       "15        0.055787               10  \n",
       "16        0.053452               17  \n",
       "17        0.055787               10  \n",
       "18        0.069985               17  \n",
       "19        0.067386               20  \n",
       "20        0.069985               17  \n",
       "21        0.071429               23  \n",
       "22        0.084515               23  \n",
       "23        0.087190               20  \n",
       "24        0.084515               25  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here...\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "X = wine_df_train\n",
    "y = list(outcome_train[\"class\"])\n",
    "\n",
    "parms_grid = {\n",
    "    \"n_neighbors\": range(1, 50, 2),\n",
    "}\n",
    "\n",
    "wine_tune_grid =GridSearchCV(\n",
    "    estimator= knn,\n",
    "    param_grid= parms_grid,\n",
    "    cv = 10\n",
    "\n",
    ")\n",
    "wine_tune_grid.fit(\n",
    "    wine_df_train,\n",
    "    list(outcome_train[\"class\"])\n",
    ")\n",
    "\n",
    "accuracy_grid = pd.DataFrame(wine_tune_grid.cv_results_)\n",
    "accuracy_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7eed93f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_tune_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f76bf62",
   "metadata": {},
   "source": [
    "#### **Question 4:**\n",
    "#### Model evaluation\n",
    "\n",
    "Using the best value for `n_neighbors`, fit a KNN model on the training data and evaluate its performance on the test set using `accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ffefa9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.004057    0.003585    1.000000\n",
       "1  0.001720    0.002625    0.928571\n",
       "2  0.000956    0.001138    0.928571\n",
       "3  0.000526    0.000906    1.000000\n",
       "4  0.000490    0.000875    1.000000\n",
       "5  0.000479    0.000881    0.928571\n",
       "6  0.000476    0.001161    1.000000\n",
       "7  0.000953    0.001322    1.000000\n",
       "8  0.000700    0.000985    0.928571\n",
       "9  0.000494    0.001235    1.000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here...\n",
    "#git the model on the training data\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "X = wine_df_train\n",
    "y = list(outcome_train[\"class\"])\n",
    "knn.fit(X, y)\n",
    "\n",
    "returned_dictionary = cross_validate(\n",
    "    estimator=knn,\n",
    "    cv=10,   \n",
    "    X=X,\n",
    "    y=y\n",
    ")\n",
    "\n",
    "cv_10_wine_train = pd.DataFrame(returned_dictionary)    \n",
    "\n",
    "cv_10_wine_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4f9e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/1l6yc2bx3m56rxmdpbz1z5w80000gn/T/ipykernel_4064/4040661365.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wine_df_test[\"predicted\"] = knn.predict(wine_df_test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.716255</td>\n",
       "      <td>-0.418624</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>-1.469878</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>0.328298</td>\n",
       "      <td>0.492677</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>1.367689</td>\n",
       "      <td>1.729520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.087232</td>\n",
       "      <td>1.313866</td>\n",
       "      <td>1.036228</td>\n",
       "      <td>-0.268738</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>0.184088</td>\n",
       "      <td>0.382241</td>\n",
       "      <td>-0.901297</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>-0.241413</td>\n",
       "      <td>0.318304</td>\n",
       "      <td>1.282942</td>\n",
       "      <td>0.073583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.061000</td>\n",
       "      <td>-0.616110</td>\n",
       "      <td>0.670693</td>\n",
       "      <td>-0.448909</td>\n",
       "      <td>-0.122282</td>\n",
       "      <td>0.248181</td>\n",
       "      <td>0.402320</td>\n",
       "      <td>-0.578985</td>\n",
       "      <td>-0.264388</td>\n",
       "      <td>-0.349555</td>\n",
       "      <td>0.713164</td>\n",
       "      <td>-0.143625</td>\n",
       "      <td>1.140389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.085705</td>\n",
       "      <td>-0.750759</td>\n",
       "      <td>-0.974210</td>\n",
       "      <td>-1.199622</td>\n",
       "      <td>-0.122282</td>\n",
       "      <td>0.168065</td>\n",
       "      <td>0.613153</td>\n",
       "      <td>-0.659563</td>\n",
       "      <td>-0.387033</td>\n",
       "      <td>-0.587469</td>\n",
       "      <td>0.976405</td>\n",
       "      <td>0.110615</td>\n",
       "      <td>0.869707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.061000</td>\n",
       "      <td>-0.508390</td>\n",
       "      <td>-0.974210</td>\n",
       "      <td>-0.749194</td>\n",
       "      <td>0.509638</td>\n",
       "      <td>1.129464</td>\n",
       "      <td>0.974581</td>\n",
       "      <td>-0.659563</td>\n",
       "      <td>0.769342</td>\n",
       "      <td>-0.007825</td>\n",
       "      <td>-0.339797</td>\n",
       "      <td>1.042827</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.110975</td>\n",
       "      <td>-0.589180</td>\n",
       "      <td>-0.901103</td>\n",
       "      <td>-1.049479</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>1.289697</td>\n",
       "      <td>1.366128</td>\n",
       "      <td>-1.223610</td>\n",
       "      <td>0.962071</td>\n",
       "      <td>0.450699</td>\n",
       "      <td>-0.208177</td>\n",
       "      <td>1.014578</td>\n",
       "      <td>0.758249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.024507</td>\n",
       "      <td>-0.616110</td>\n",
       "      <td>0.853460</td>\n",
       "      <td>-0.689137</td>\n",
       "      <td>-0.403135</td>\n",
       "      <td>0.248181</td>\n",
       "      <td>0.964541</td>\n",
       "      <td>-1.143031</td>\n",
       "      <td>1.224884</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>1.239645</td>\n",
       "      <td>1.071076</td>\n",
       "      <td>1.649908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.888627</td>\n",
       "      <td>-0.813595</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>-0.839280</td>\n",
       "      <td>0.579852</td>\n",
       "      <td>1.770396</td>\n",
       "      <td>1.647239</td>\n",
       "      <td>-1.384766</td>\n",
       "      <td>0.786863</td>\n",
       "      <td>0.753498</td>\n",
       "      <td>-0.295924</td>\n",
       "      <td>0.364855</td>\n",
       "      <td>1.713598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.026033</td>\n",
       "      <td>-0.795642</td>\n",
       "      <td>0.597587</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>0.298998</td>\n",
       "      <td>-0.649124</td>\n",
       "      <td>-0.280377</td>\n",
       "      <td>0.710264</td>\n",
       "      <td>-0.982742</td>\n",
       "      <td>-0.911896</td>\n",
       "      <td>2.160986</td>\n",
       "      <td>-0.539109</td>\n",
       "      <td>-1.247982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.135116</td>\n",
       "      <td>-1.190614</td>\n",
       "      <td>-2.436346</td>\n",
       "      <td>-1.349764</td>\n",
       "      <td>-1.526548</td>\n",
       "      <td>1.097417</td>\n",
       "      <td>1.155295</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>1.207363</td>\n",
       "      <td>0.104643</td>\n",
       "      <td>0.713164</td>\n",
       "      <td>0.802712</td>\n",
       "      <td>-0.779861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.061565</td>\n",
       "      <td>-0.741782</td>\n",
       "      <td>1.109334</td>\n",
       "      <td>1.653086</td>\n",
       "      <td>-0.964842</td>\n",
       "      <td>1.049347</td>\n",
       "      <td>0.834026</td>\n",
       "      <td>-1.223610</td>\n",
       "      <td>0.489009</td>\n",
       "      <td>-0.725891</td>\n",
       "      <td>1.766126</td>\n",
       "      <td>0.774463</td>\n",
       "      <td>-1.072834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.433671</td>\n",
       "      <td>-1.298334</td>\n",
       "      <td>0.780354</td>\n",
       "      <td>-0.448909</td>\n",
       "      <td>-0.403135</td>\n",
       "      <td>-0.152402</td>\n",
       "      <td>0.181447</td>\n",
       "      <td>-1.143031</td>\n",
       "      <td>1.330009</td>\n",
       "      <td>-0.868639</td>\n",
       "      <td>-0.734657</td>\n",
       "      <td>0.661468</td>\n",
       "      <td>-0.722540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.408401</td>\n",
       "      <td>-1.217544</td>\n",
       "      <td>-0.462462</td>\n",
       "      <td>-0.448909</td>\n",
       "      <td>-0.052068</td>\n",
       "      <td>-0.152402</td>\n",
       "      <td>-0.089624</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>-0.229346</td>\n",
       "      <td>-1.054644</td>\n",
       "      <td>1.195772</td>\n",
       "      <td>0.774463</td>\n",
       "      <td>-0.945455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-1.236028</td>\n",
       "      <td>-0.741782</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.752231</td>\n",
       "      <td>-0.964842</td>\n",
       "      <td>-1.354150</td>\n",
       "      <td>-0.782361</td>\n",
       "      <td>1.113154</td>\n",
       "      <td>0.068508</td>\n",
       "      <td>-0.630726</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>0.054117</td>\n",
       "      <td>-0.945455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.877801</td>\n",
       "      <td>0.443133</td>\n",
       "      <td>-0.535569</td>\n",
       "      <td>-0.448909</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>0.248181</td>\n",
       "      <td>0.221606</td>\n",
       "      <td>-0.901297</td>\n",
       "      <td>0.699259</td>\n",
       "      <td>-1.257952</td>\n",
       "      <td>0.844785</td>\n",
       "      <td>0.972205</td>\n",
       "      <td>-1.454974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.927212</td>\n",
       "      <td>-0.544297</td>\n",
       "      <td>-0.901103</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>-1.386122</td>\n",
       "      <td>-1.033684</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.065639</td>\n",
       "      <td>0.068508</td>\n",
       "      <td>-0.717240</td>\n",
       "      <td>0.186684</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>-0.754385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.964270</td>\n",
       "      <td>-0.939268</td>\n",
       "      <td>-1.559065</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>-0.543562</td>\n",
       "      <td>0.103972</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>0.856946</td>\n",
       "      <td>-1.020039</td>\n",
       "      <td>-0.427544</td>\n",
       "      <td>0.576721</td>\n",
       "      <td>-1.384915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-1.964835</td>\n",
       "      <td>-1.432983</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>0.296251</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>0.468530</td>\n",
       "      <td>-0.264388</td>\n",
       "      <td>-0.855662</td>\n",
       "      <td>0.625418</td>\n",
       "      <td>-0.426113</td>\n",
       "      <td>-0.996407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.236028</td>\n",
       "      <td>0.981731</td>\n",
       "      <td>-1.339744</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>-0.894628</td>\n",
       "      <td>-0.472868</td>\n",
       "      <td>-0.390814</td>\n",
       "      <td>0.065639</td>\n",
       "      <td>0.489009</td>\n",
       "      <td>-1.634288</td>\n",
       "      <td>-0.120430</td>\n",
       "      <td>0.619094</td>\n",
       "      <td>-0.582422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-1.915424</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.763748</td>\n",
       "      <td>-0.337251</td>\n",
       "      <td>0.418925</td>\n",
       "      <td>-0.782125</td>\n",
       "      <td>-0.690784</td>\n",
       "      <td>1.099325</td>\n",
       "      <td>-0.388168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-1.396613</td>\n",
       "      <td>1.771674</td>\n",
       "      <td>0.085839</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>-1.245695</td>\n",
       "      <td>0.905137</td>\n",
       "      <td>1.004700</td>\n",
       "      <td>-1.223610</td>\n",
       "      <td>2.311176</td>\n",
       "      <td>-0.976782</td>\n",
       "      <td>-0.910151</td>\n",
       "      <td>1.452436</td>\n",
       "      <td>-1.168369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-1.149560</td>\n",
       "      <td>-0.158301</td>\n",
       "      <td>-0.718336</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>-1.035055</td>\n",
       "      <td>0.488531</td>\n",
       "      <td>0.623193</td>\n",
       "      <td>0.065639</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>-0.994085</td>\n",
       "      <td>-0.427544</td>\n",
       "      <td>0.943956</td>\n",
       "      <td>-1.174738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-0.778980</td>\n",
       "      <td>-0.634063</td>\n",
       "      <td>-0.243142</td>\n",
       "      <td>1.502943</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>-0.120355</td>\n",
       "      <td>0.422399</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>0.541571</td>\n",
       "      <td>-1.270929</td>\n",
       "      <td>-0.295924</td>\n",
       "      <td>0.237735</td>\n",
       "      <td>-1.289380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-0.371343</td>\n",
       "      <td>1.089450</td>\n",
       "      <td>-0.023821</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>0.439425</td>\n",
       "      <td>-0.953567</td>\n",
       "      <td>-0.832559</td>\n",
       "      <td>-1.545922</td>\n",
       "      <td>-1.315638</td>\n",
       "      <td>-0.025128</td>\n",
       "      <td>-0.778531</td>\n",
       "      <td>-1.866805</td>\n",
       "      <td>-0.467781</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.606043</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>-0.425909</td>\n",
       "      <td>-0.599052</td>\n",
       "      <td>-1.035055</td>\n",
       "      <td>-0.472868</td>\n",
       "      <td>-1.455019</td>\n",
       "      <td>1.918935</td>\n",
       "      <td>-0.597284</td>\n",
       "      <td>0.169529</td>\n",
       "      <td>-0.910151</td>\n",
       "      <td>-1.556068</td>\n",
       "      <td>-0.308556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.641574</td>\n",
       "      <td>0.748338</td>\n",
       "      <td>1.292101</td>\n",
       "      <td>1.202658</td>\n",
       "      <td>-0.192495</td>\n",
       "      <td>-1.193917</td>\n",
       "      <td>-1.515257</td>\n",
       "      <td>1.113154</td>\n",
       "      <td>-1.823742</td>\n",
       "      <td>-0.306298</td>\n",
       "      <td>-0.295924</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.722540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.196879</td>\n",
       "      <td>1.107404</td>\n",
       "      <td>-0.791443</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>-1.274034</td>\n",
       "      <td>-1.485138</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.509679</td>\n",
       "      <td>-0.457698</td>\n",
       "      <td>-1.568252</td>\n",
       "      <td>-1.315952</td>\n",
       "      <td>0.264653</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.098058</td>\n",
       "      <td>1.403632</td>\n",
       "      <td>-0.023821</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>0.930918</td>\n",
       "      <td>-1.418243</td>\n",
       "      <td>-0.641805</td>\n",
       "      <td>-0.176095</td>\n",
       "      <td>-0.790013</td>\n",
       "      <td>1.878180</td>\n",
       "      <td>-1.699872</td>\n",
       "      <td>-1.810307</td>\n",
       "      <td>-0.627005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.260169</td>\n",
       "      <td>0.299507</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>0.752231</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>-1.306080</td>\n",
       "      <td>-0.671924</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>-0.579763</td>\n",
       "      <td>2.483778</td>\n",
       "      <td>-2.094732</td>\n",
       "      <td>-1.612565</td>\n",
       "      <td>-0.849920</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.680159</td>\n",
       "      <td>0.622666</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>2.253656</td>\n",
       "      <td>-0.192495</td>\n",
       "      <td>-0.633101</td>\n",
       "      <td>-1.455019</td>\n",
       "      <td>2.160669</td>\n",
       "      <td>-0.790013</td>\n",
       "      <td>1.056297</td>\n",
       "      <td>-1.261138</td>\n",
       "      <td>-1.245330</td>\n",
       "      <td>0.423878</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.851569</td>\n",
       "      <td>0.829128</td>\n",
       "      <td>0.634140</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>0.509638</td>\n",
       "      <td>-0.745264</td>\n",
       "      <td>-1.475098</td>\n",
       "      <td>1.113154</td>\n",
       "      <td>-1.385721</td>\n",
       "      <td>0.355534</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>-1.118210</td>\n",
       "      <td>-0.213021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.900980</td>\n",
       "      <td>1.816558</td>\n",
       "      <td>-0.389355</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>-1.626547</td>\n",
       "      <td>-1.565455</td>\n",
       "      <td>1.274310</td>\n",
       "      <td>-0.772492</td>\n",
       "      <td>0.675635</td>\n",
       "      <td>-0.778531</td>\n",
       "      <td>-1.217081</td>\n",
       "      <td>-0.722540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.223111</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>-0.243142</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>-1.306080</td>\n",
       "      <td>-1.374701</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>-1.087867</td>\n",
       "      <td>2.250190</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>-1.217081</td>\n",
       "      <td>-0.197099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.715690</td>\n",
       "      <td>0.218717</td>\n",
       "      <td>1.182441</td>\n",
       "      <td>1.502943</td>\n",
       "      <td>0.369212</td>\n",
       "      <td>-1.193917</td>\n",
       "      <td>-1.193987</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>-0.089179</td>\n",
       "      <td>1.558078</td>\n",
       "      <td>-0.954024</td>\n",
       "      <td>-1.146459</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.988975</td>\n",
       "      <td>0.622666</td>\n",
       "      <td>-0.170035</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>-1.674617</td>\n",
       "      <td>-1.545376</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>-1.508367</td>\n",
       "      <td>0.191157</td>\n",
       "      <td>-1.305011</td>\n",
       "      <td>-1.104086</td>\n",
       "      <td>-0.754385</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.432144</td>\n",
       "      <td>0.155881</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>-0.613775</td>\n",
       "      <td>-0.985614</td>\n",
       "      <td>-1.334543</td>\n",
       "      <td>0.629686</td>\n",
       "      <td>-0.614804</td>\n",
       "      <td>2.007951</td>\n",
       "      <td>-1.480505</td>\n",
       "      <td>-1.273579</td>\n",
       "      <td>-0.276711</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.876275</td>\n",
       "      <td>2.974543</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>0.301803</td>\n",
       "      <td>-0.332922</td>\n",
       "      <td>-0.985614</td>\n",
       "      <td>-1.424900</td>\n",
       "      <td>1.274310</td>\n",
       "      <td>-0.930179</td>\n",
       "      <td>1.142811</td>\n",
       "      <td>-1.392758</td>\n",
       "      <td>-1.231206</td>\n",
       "      <td>-0.021952</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.493343</td>\n",
       "      <td>1.412609</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>1.052516</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>-0.793334</td>\n",
       "      <td>-1.284344</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.316950</td>\n",
       "      <td>0.969783</td>\n",
       "      <td>-1.129518</td>\n",
       "      <td>-1.485445</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "6    1.716255   -0.418624  0.305159          -1.469878  -0.262708   \n",
       "21  -0.087232    1.313866  1.036228          -0.268738   0.158572   \n",
       "37   0.061000   -0.616110  0.670693          -0.448909  -0.122282   \n",
       "38   0.085705   -0.750759 -0.974210          -1.199622  -0.122282   \n",
       "44   0.061000   -0.508390 -0.974210          -0.749194   0.509638   \n",
       "47   1.110975   -0.589180 -0.901103          -1.049479   0.088358   \n",
       "51   1.024507   -0.616110  0.853460          -0.689137  -0.403135   \n",
       "58   0.888627   -0.813595  0.487926          -0.839280   0.579852   \n",
       "64  -1.026033   -0.795642  0.597587          -0.148624   0.298998   \n",
       "66   0.135116   -1.190614 -2.436346          -1.349764  -1.526548   \n",
       "71   1.061565   -0.741782  1.109334           1.653086  -0.964842   \n",
       "84  -1.433671   -1.298334  0.780354          -0.448909  -0.403135   \n",
       "85  -0.408401   -1.217544 -0.462462          -0.448909  -0.052068   \n",
       "91  -1.236028   -0.741782  0.195499           0.752231  -0.964842   \n",
       "93  -0.877801    0.443133 -0.535569          -0.448909  -0.824415   \n",
       "106 -0.927212   -0.544297 -0.901103          -0.148624  -1.386122   \n",
       "108 -0.964270   -0.939268 -1.559065          -0.148624  -0.543562   \n",
       "113 -1.964835   -1.432983  0.487926           0.451946  -0.824415   \n",
       "119 -1.236028    0.981731 -1.339744          -0.148624  -0.894628   \n",
       "120 -1.915424    0.057138  0.195499           0.151661  -0.262708   \n",
       "124 -1.396613    1.771674  0.085839           0.451946  -1.245695   \n",
       "125 -1.149560   -0.158301 -0.718336           0.451946  -1.035055   \n",
       "128 -0.778980   -0.634063 -0.243142           1.502943  -0.824415   \n",
       "133 -0.371343    1.089450 -0.023821           0.602088   0.439425   \n",
       "134 -0.606043   -0.984151 -0.425909          -0.599052  -1.035055   \n",
       "142  0.641574    0.748338  1.292101           1.202658  -0.192495   \n",
       "145  0.196879    1.107404 -0.791443           0.451946   0.158572   \n",
       "149  0.098058    1.403632 -0.023821           0.602088   0.930918   \n",
       "151 -0.260169    0.299507  0.414820           0.752231   0.860705   \n",
       "157 -0.680159    0.622666  0.999674           2.253656  -0.192495   \n",
       "161  0.851569    0.829128  0.634140           0.151661   0.509638   \n",
       "165  0.900980    1.816558 -0.389355           0.902373  -0.824415   \n",
       "167 -0.223111    0.927871 -0.243142           0.001518  -0.824415   \n",
       "168  0.715690    0.218717  1.182441           1.502943   0.369212   \n",
       "170 -0.988975    0.622666 -0.170035          -0.148624  -0.262708   \n",
       "172  1.432144    0.155881  0.414820           0.151661  -0.613775   \n",
       "173  0.876275    2.974543  0.305159           0.301803  -0.332922   \n",
       "174  0.493343    1.412609  0.414820           1.052516   0.158572   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "6         0.328298    0.492677             -0.498407         0.681738   \n",
       "21        0.184088    0.382241             -0.901297         0.681738   \n",
       "37        0.248181    0.402320             -0.578985        -0.264388   \n",
       "38        0.168065    0.613153             -0.659563        -0.387033   \n",
       "44        1.129464    0.974581             -0.659563         0.769342   \n",
       "47        1.289697    1.366128             -1.223610         0.962071   \n",
       "51        0.248181    0.964541             -1.143031         1.224884   \n",
       "58        1.770396    1.647239             -1.384766         0.786863   \n",
       "64       -0.649124   -0.280377              0.710264        -0.982742   \n",
       "66        1.097417    1.155295             -0.820719         1.207363   \n",
       "71        1.049347    0.834026             -1.223610         0.489009   \n",
       "84       -0.152402    0.181447             -1.143031         1.330009   \n",
       "85       -0.152402   -0.089624             -0.498407        -0.229346   \n",
       "91       -1.354150   -0.782361              1.113154         0.068508   \n",
       "93        0.248181    0.221606             -0.901297         0.699259   \n",
       "106      -1.033684    0.000733              0.065639         0.068508   \n",
       "108       0.103972    0.010773              0.226796         0.856946   \n",
       "113       0.296251   -0.019346              0.468530        -0.264388   \n",
       "119      -0.472868   -0.390814              0.065639         0.489009   \n",
       "120       0.969231    0.763748             -0.337251         0.418925   \n",
       "124       0.905137    1.004700             -1.223610         2.311176   \n",
       "125       0.488531    0.623193              0.065639        -0.422075   \n",
       "128      -0.120355    0.422399              0.307374         0.541571   \n",
       "133      -0.953567   -0.832559             -1.545922        -1.315638   \n",
       "134      -0.472868   -1.455019              1.918935        -0.597284   \n",
       "142      -1.193917   -1.515257              1.113154        -1.823742   \n",
       "145      -1.274034   -1.485138              0.549108        -0.509679   \n",
       "149      -1.418243   -0.641805             -0.176095        -0.790013   \n",
       "151      -1.306080   -0.671924             -0.981875        -0.579763   \n",
       "157      -0.633101   -1.455019              2.160669        -0.790013   \n",
       "161      -0.745264   -1.475098              1.113154        -1.385721   \n",
       "165      -1.626547   -1.565455              1.274310        -0.772492   \n",
       "167      -1.306080   -1.374701              0.307374        -1.087867   \n",
       "168      -1.193917   -1.193987              0.226796        -0.089179   \n",
       "170      -1.674617   -1.545376              0.307374        -1.508367   \n",
       "172      -0.985614   -1.334543              0.629686        -0.614804   \n",
       "173      -0.985614   -1.424900              1.274310        -0.930179   \n",
       "174      -0.793334   -1.284344              0.549108        -0.316950   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \\\n",
       "6           0.083015  0.274431                      1.367689  1.729520   \n",
       "21         -0.241413  0.318304                      1.282942  0.073583   \n",
       "37         -0.349555  0.713164                     -0.143625  1.140389   \n",
       "38         -0.587469  0.976405                      0.110615  0.869707   \n",
       "44         -0.007825 -0.339797                      1.042827  0.439800   \n",
       "47          0.450699 -0.208177                      1.014578  0.758249   \n",
       "51          0.234414  1.239645                      1.071076  1.649908   \n",
       "58          0.753498 -0.295924                      0.364855  1.713598   \n",
       "64         -0.911896  2.160986                     -0.539109 -1.247982   \n",
       "66          0.104643  0.713164                      0.802712 -0.779861   \n",
       "71         -0.725891  1.766126                      0.774463 -1.072834   \n",
       "84         -0.868639 -0.734657                      0.661468 -0.722540   \n",
       "85         -1.054644  1.195772                      0.774463 -0.945455   \n",
       "91         -0.630726  0.406051                      0.054117 -0.945455   \n",
       "93         -1.257952  0.844785                      0.972205 -1.454974   \n",
       "106        -0.717240  0.186684                      0.788587 -0.754385   \n",
       "108        -1.020039 -0.427544                      0.576721 -1.384915   \n",
       "113        -0.855662  0.625418                     -0.426113 -0.996407   \n",
       "119        -1.634288 -0.120430                      0.619094 -0.582422   \n",
       "120        -0.782125 -0.690784                      1.099325 -0.388168   \n",
       "124        -0.976782 -0.910151                      1.452436 -1.168369   \n",
       "125        -0.994085 -0.427544                      0.943956 -1.174738   \n",
       "128        -1.270929 -0.295924                      0.237735 -1.289380   \n",
       "133        -0.025128 -0.778531                     -1.866805 -0.467781   \n",
       "134         0.169529 -0.910151                     -1.556068 -0.308556   \n",
       "142        -0.306298 -0.295924                     -0.779224 -0.722540   \n",
       "145        -0.457698 -1.568252                     -1.315952  0.264653   \n",
       "149         1.878180 -1.699872                     -1.810307 -0.627005   \n",
       "151         2.483778 -2.094732                     -1.612565 -0.849920   \n",
       "157         1.056297 -1.261138                     -1.245330  0.423878   \n",
       "161         0.355534  0.011190                     -1.118210 -0.213021   \n",
       "165         0.675635 -0.778531                     -1.217081 -0.722540   \n",
       "167         2.250190 -1.041771                     -1.217081 -0.197099   \n",
       "168         1.558078 -0.954024                     -1.146459  0.009893   \n",
       "170         0.191157 -1.305011                     -1.104086 -0.754385   \n",
       "172         2.007951 -1.480505                     -1.273579 -0.276711   \n",
       "173         1.142811 -1.392758                     -1.231206 -0.021952   \n",
       "174         0.969783 -1.129518                     -1.485445  0.009893   \n",
       "\n",
       "     predicted  \n",
       "6            0  \n",
       "21           0  \n",
       "37           0  \n",
       "38           0  \n",
       "44           0  \n",
       "47           0  \n",
       "51           0  \n",
       "58           0  \n",
       "64           1  \n",
       "66           1  \n",
       "71           0  \n",
       "84           1  \n",
       "85           1  \n",
       "91           1  \n",
       "93           1  \n",
       "106          1  \n",
       "108          1  \n",
       "113          1  \n",
       "119          1  \n",
       "120          1  \n",
       "124          1  \n",
       "125          1  \n",
       "128          1  \n",
       "133          2  \n",
       "134          2  \n",
       "142          2  \n",
       "145          2  \n",
       "149          2  \n",
       "151          2  \n",
       "157          2  \n",
       "161          2  \n",
       "165          2  \n",
       "167          2  \n",
       "168          2  \n",
       "170          2  \n",
       "172          2  \n",
       "173          2  \n",
       "174          2  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model on the testing data\n",
    "\n",
    "wine_df_test[\"predicted\"] = knn.predict(wine_df_test)\n",
    "wine_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "81931c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score function - accuracy 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#evalute the accuracy of the model\n",
    "accuracy = accuracy_score(outcome_test, wine_df_test[\"predicted\"] )\n",
    "print( f\"accuracy_score function - accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc53f72",
   "metadata": {},
   "source": [
    "code from https://www.geeksforgeeks.org/difference-between-score-and-accuracy_score-methods-in-scikit-learn/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a69db",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    "\n",
    "| **Criteria**                                           | **Complete**                                      | **Incomplete**                                    |\n",
    "|--------------------------------------------------------|---------------------------------------------------|--------------------------------------------------|\n",
    "| **Data Inspection**                                    | Data is inspected for number of variables, observations and data types. | Data inspection is missing or incomplete.         |\n",
    "| **Data Scaling**                                       | Data scaling or normalization is applied where necessary (e.g., using `StandardScaler`). | Data scaling or normalization is missing or incorrectly applied. |\n",
    "| **Model Initialization**                               | The KNN model is correctly initialized and a random seed is set for reproducibility.            | The KNN model is not initialized, is incorrect, or lacks a random seed for reproducibility. |\n",
    "| **Parameter Grid for `n_neighbors`**                   | The parameter grid for `n_neighbors` is correctly defined. | The parameter grid is missing or incorrectly defined. |\n",
    "| **Cross-Validation Setup**                             | Cross-validation is set up correctly with 10 folds. | Cross-validation is missing or incorrectly set up. |\n",
    "| **Best Hyperparameter (`n_neighbors`) Selection**       | The best value for `n_neighbors` is identified using the grid search results. | The best `n_neighbors` is not selected or incorrect. |\n",
    "| **Model Evaluation on Test Data**                      | The model is evaluated on the test data using accuracy. | The model evaluation is missing or uses the wrong metric. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4390cc",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Note:\n",
    "\n",
    "If you like, you may collaborate with others in the cohort. If you choose to do so, please indicate with whom you have worked with in your pull request by tagging their GitHub username. Separate submissions are required.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/applying_statistical_concepts/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-4-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
